{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "_rotation = 20 \n",
    "_zoom = 0.5\n",
    "_flip = True\n",
    "_batch_size = 128\n",
    "_random_state = 42\n",
    "_input_shape = (150, 150, 3)\n",
    "_dropout = 0.6\n",
    "_alpha = 1e-5\n",
    "_epochs = 10\n",
    "_hidden_unit = 32\n",
    "_kernel_size = 3\n",
    "_trainable_layer = 'block5_conv1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def select_image(filename):\n",
    "    _image = Image.open(filename)\n",
    "    _image = _image.convert('RGB')\n",
    "    _image = _image.resize((150,150))\n",
    "    return np.asarray(_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_class(directory, label_class, images, labels):\n",
    "    for filename in os.listdir(directory):\n",
    "        _path = directory + filename\n",
    "        images.append(select_image(_path))\n",
    "        labels.append(label_class)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_dataset(directory):\n",
    "    _images = list()\n",
    "    _labels = list()\n",
    "    for subdir in os.listdir(directory):\n",
    "        _path = directory + subdir + '/'\n",
    "        if not os.path.isdir(_path):\n",
    "            continue\n",
    "        _images, _labels = load_class(_path, subdir, _images, _labels)\n",
    "    return _images, _labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190 190\n"
     ]
    }
   ],
   "source": [
    "_images, _labels = select_dataset(os.getcwd() + '\\\\data2\\\\')\n",
    "print(len(_images), len(_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "_labelBinarizer = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "def normalize(images, labels):\n",
    "    images = np.array(images) / 255.0\n",
    "    labels = np.array(labels)\n",
    "    labels = _labelBinarizer.fit_transform(labels)\n",
    "    labels = to_categorical(labels)\n",
    "    return images, labels\n",
    "\n",
    "_images, _labels = normalize(_images, _labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "_x_train, _x_test, _y_train, _y_test = train_test_split(_images, _labels, test_size=0.20, stratify=_labels, random_state=_random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "_train_data_augmentation = ImageDataGenerator(rotation_range=_rotation, zoom_range=_zoom, horizontal_flip=_flip)\n",
    "_train_data_augmentation.fit(_x_train)\n",
    "_data_augmentation = _train_data_augmentation.flow(_x_train, _y_train, batch_size=_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CallBacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "def _get_callbacks(model_name, verbose=1):\n",
    "    _checkpoint = ModelCheckpoint(os.getcwd() + f'\\\\models\\\\{model_name}.hdf5', monitor='val_acc', save_best_only=True, mode='max', verbose=verbose)\n",
    "    _plateau = ReduceLROnPlateau(monitor='val_acc', factor=0.1, min_delta=_alpha, patience=5, verbose=verbose)\n",
    "    return [_checkpoint, _plateau]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 18:21:45 ] ========= Denso =========\n",
      "[ 18:21:46 ] Quantidade de Épocas: 5\n",
      "[ 18:23:19 ] Acurácia: 0.9473684430122375\n",
      "[ 18:23:19 ] Quantidade de Épocas: 10\n",
      "[ 18:26:24 ] Acurácia: 1.0\n",
      "[ 18:26:24 ] Quantidade de Épocas: 20\n",
      "[ 18:32:24 ] Acurácia: 1.0\n",
      "\n",
      "[ 18:32:24 ] ========= LSTM =========\n",
      "[ 18:32:24 ] Quantidade de Épocas: 5\n",
      "[ 18:34:28 ] Acurácia: 0.7105262875556946\n",
      "[ 18:34:28 ] Quantidade de Épocas: 10\n",
      "[ 18:38:22 ] Acurácia: 0.8092105388641357\n",
      "[ 18:38:22 ] Quantidade de Épocas: 20\n",
      "[ 18:45:48 ] Acurácia: 0.9078947305679321\n",
      "\n",
      "[ 18:45:48 ] ========= BiLSTM =========\n",
      "[ 18:45:50 ] Quantidade de Épocas: 5\n",
      "[ 18:48:35 ] Acurácia: 0.8026315569877625\n",
      "[ 18:48:35 ] Quantidade de Épocas: 10\n",
      "[ 18:53:44 ] Acurácia: 0.9473684430122375\n",
      "[ 18:53:44 ] Quantidade de Épocas: 20\n",
      "[ 19:03:38 ] Acurácia: 0.9473684430122375\n",
      "\n",
      "[ 19:03:38 ] ========= BiGRU =========\n",
      "[ 19:03:38 ] Quantidade de Épocas: 5\n",
      "[ 19:06:24 ] Acurácia: 0.5526315569877625\n",
      "[ 19:06:24 ] Quantidade de Épocas: 10\n",
      "[ 19:11:08 ] Acurácia: 0.7894737124443054\n",
      "[ 19:11:08 ] Quantidade de Épocas: 20\n",
      "[ 19:20:23 ] Acurácia: 0.7894737124443054\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "_epochs = [5, 10, 20]\n",
    "_models = {\n",
    "    'Denso': [],\n",
    "    'LSTM': [LSTM(32, return_sequences=False)],\n",
    "    'BiLSTM': [Bidirectional(LSTM(32, return_sequences=True)), Bidirectional(LSTM(32, return_sequences=False))],\n",
    "    'BiGRU': [Bidirectional(GRU(32, return_sequences=False))],\n",
    "}\n",
    "\n",
    "\n",
    "for model in _models:\n",
    "    print('[', datetime.now().strftime(\"%H:%M:%S\"), ']', '=========', model, '=========')\n",
    "    m = Sequential()\n",
    "    m.add(Dense(254, activation ='relu', input_shape =_input_shape))\n",
    "    m.add(Dense(128, activation ='relu'))\n",
    "    m.add(Dense(64, activation ='relu'))\n",
    "    m.add(Dropout(0.25))\n",
    "    m.add(TimeDistributed(Flatten()) if len(_models[model]) > 0 else Flatten())\n",
    "    for layer in _models[model]:\n",
    "        m.add(layer)\n",
    "    m.add(Dense(2, activation ='softmax'))\n",
    "    m.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    \n",
    "    for epoch in _epochs:\n",
    "        print('[', datetime.now().strftime(\"%H:%M:%S\"), ']', 'Quantidade de Épocas:', epoch)\n",
    "        _callbacks = _get_callbacks(f'{model}_{epoch}', verbose=0)\n",
    "        m.fit_generator(_data_augmentation,\n",
    "                        epochs = epoch, \n",
    "                        validation_data = (_x_train, _y_train),\n",
    "                        verbose = 0, \n",
    "                        steps_per_epoch=_x_train.shape[0] // _batch_size, \n",
    "                        callbacks=_callbacks)\n",
    "        _result = m.evaluate(_x_train, _y_train, verbose = 0)\n",
    "        print('[', datetime.now().strftime(\"%H:%M:%S\"), ']', 'Acurácia:', _result[1])\n",
    "    print('')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
